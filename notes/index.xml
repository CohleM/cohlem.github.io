<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Notes on CohleM</title>
    <link>https://cohlem.github.io/notes/</link>
    <description>Recent content in Notes on CohleM</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 10 Jan 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://cohlem.github.io/notes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>projects</title>
      <link>https://cohlem.github.io/notes/projects/</link>
      <pubDate>Fri, 10 Jan 2025 00:00:00 +0000</pubDate>
      
      <guid>https://cohlem.github.io/notes/projects/</guid>
      <description>Fine-tuning model to generate manim code data sources
manim docs 3blue1brow&amp;rsquo;s github </description>
    </item>
    
    <item>
      <title>Essential blogs</title>
      <link>https://cohlem.github.io/notes/essential-blogs/</link>
      <pubDate>Fri, 03 Jan 2025 00:00:00 +0000</pubDate>
      
      <guid>https://cohlem.github.io/notes/essential-blogs/</guid>
      <description>Training Neural Networks Karpathy&amp;rsquo;s advice while training NN</description>
    </item>
    
    <item>
      <title>Deep Learning Notes</title>
      <link>https://cohlem.github.io/notes/deep-learning-notes/</link>
      <pubDate>Sun, 08 Dec 2024 21:57:23 +0545</pubDate>
      
      <guid>https://cohlem.github.io/notes/deep-learning-notes/</guid>
      <description>Backpropagation Backpropagation on scalars from scratch Manual Backpropagation on tensor Loss function Maximum likelihood estimate as loss function Why we add regularization to loss functio√± Optimization Optimization Algorithms (SGD with momentum, RMSProp, Adam) Optimizing loss with weight initialization BatchNormalization RMSNorm Diagnostic tool to look out for while training NN Skip Connections Training Misc Matrix Visualization Architecture Implementation GPT implementation MoE GPU </description>
    </item>
    
  </channel>
</rss>
