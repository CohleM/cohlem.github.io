<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Home - </title>
    <link rel="stylesheet" href="/assets/css/main.css" />

    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Zalando+Sans+Expanded:ital,wght@0,200..900;1,200..900&family=Zalando+Sans:ital,wght@0,200..900;1,200..900&display=swap"
      rel="stylesheet"
    />
  </head>
  <body>
    <nav>
      <a href="/">Home</a>
      <a href="/blog">Blog</a>
    </nav>

    <main><div class="home-container">
    <section class="hero">
  <h2>Hi, I'm Manish</h2>
  <p class="subtitle">

     I graduated with a BS in Computer Science from Kathmandu
University where I was advised by
<a href='https://ku.edu.np/contact-detail/bal-krishna-bal' target='_blank'>Prof. Dr. Bal Krishna Bal</a>.
As of now, my research interests include, but are not limited to:
 
     <ul>
        
          <li>> <strong>LLM Post-Training</strong>: RL is supposed to elicit reasoning in LLMs
by expanding inference-time compute. However, this training process is only
limited to verifiable domains (code, math) whereas the majority of tasks
that justify productivity are not verifiable. Does RL help here? Do we need
a different paradigm? I intend to explore this.
</li>
        
          <li>> <strong>Multi-agent</strong>: Current research focuses on building agents that
are good at tool calling, but still tools are called more often than required.
When should LLMs simply use their parametric knowledge and when use the tools?
Agents are used only during inference time. Can we orchestrate multi-agents for
training tasks like these?
</li>
        
      </ul>
      
  </p>
</section>

<section class="Publications">
    <h2>Publications</h2>
    <ul>
      
        <li>
          <p>
            <strong>Nepali Encoder Transformers</strong>
            <a href="https://aclanthology.org/2022.sigul-1.14.pdf" target="_blank" rel="noopener">[PDF]</a><br>
            Proceedings of SIGUL2022 @ LREC2022<br>
            Utsav Maskey, Manish Bhatta, Shiva Raj Bhatta, Sanket Dhungel, Bal Krishna Bal
          </p>
        </li>
      
    </ul>
  </section>

  <section class="projects">
    <h2>Projects</h2>
    <ul>
      
        <li>
          <p>
            <strong>LilLM</strong>
            <a href="https://github.com/CohleM/lilLM" target="_blank" rel="noopener">[github]</a><br>
            &gt; pre-training 39M parameter and supervised fine-tuning Llama like model from scratch
          </p>
        </li>
      
        <li>
          <p>
            <strong>RL-GRPO</strong>
            <a href="https://github.com/CohleM/RL-GRPO" target="_blank" rel="noopener">[github]</a><br>
            &gt; distributed training (FSDP, tensor parallelism) of qwen model using GRPO algorithm under 1000 LOC
          </p>
        </li>
      
    </ul>
  </section>
  

<section class="blogs">
  <h2>Blogs</h2>
  <ul>
    <li>Skill 1 </li>
    <li>Skill 2</li>
    <li>Skill 3</li>
  </ul>
</section>

<section class="contact">
  <h2>Get in Touch</h2>
  <p>Email: your@email.com</p>
</section>

</div>
</main>

    <footer>
      <p>&copy; 2025 </p>
    </footer>
  </body>
</html>
